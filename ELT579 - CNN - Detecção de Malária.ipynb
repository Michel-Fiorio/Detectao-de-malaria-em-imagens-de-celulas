{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Universidade Federal de Viçosa</center>\n",
    "<center>Inteligência Artificial e Computacional</center>\n",
    "<center>ELT579 - Tópicos Especiais em Inteligência Artificial</center>\n",
    "<center>TURMA 2022/2</center>\n",
    "\n",
    "**<center>Semana 4: Detecção de malária em imagens de células </center>**\n",
    "<center>Aluno: Michel Batistin Fiorio</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo:**\n",
    "Durante as aulas da quarta semana do curso foi implementada uma CNN para classificação de imagens de células humanas em dois grupos, o de células com malária e de células sem malária. \n",
    "\n",
    "Utilizando um banco de dados de 2000 imagens de células (1000 células doentes e 1000 células saudáveis) o algoritmo desenvolvido em aula obteve uma precisão de 96% na inferência das imagens de teste. \n",
    "\n",
    "O objetivo dessa atividade é implementar melhorias no algoritmo para que o resultado do modelo supere o resultado obtido em aula.\n",
    "\n",
    "**Alterações relevantes realizadas no modelo final:**\n",
    "- Utilização do banco de dados completo disponível. 22558 imagens, sendo metade das imagens de células positivas, metade de células negativas. Destas, foram realizadas os seguintes agrupamentos:\n",
    "    - 18047 imagens utilizadas para treinamento\n",
    "    - 4511 imagens de validação\n",
    "    - 5000 imagens de teste\n",
    "- Foram adicionados no modelo camadas de aumento de dados. As camadas utilizadas foram RandomFlip, RandomRotation, RandomZoom.\n",
    "- Foram adicionadas 2 camadas convolucionais de 32 filtros. \n",
    "- Foi alterada a função de ativação da camada de saída para sigmoid e reduzida de 2 para 1 neurônio.\n",
    "- Foi alterada a função perda de treinamento para binary_crossentropy.\n",
    "- Foi adicionado uma função de parada prematura no treinamento da CNN. Configurado para monitorar o 'val_loss' e parar o treinamento após 10 épocas sem redução do índice. \n",
    "\n",
    "**Resultados alcançados:**\n",
    "Após testarmos inumeras configurações de pré-processamento dos dados e na estrutura da CNN, o melhor resultado alcançado na ativididade foi uma precisão de 96,24% nos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 4324,
     "status": "ok",
     "timestamp": 1651758734143,
     "user": {
      "displayName": "Sarvio Valente",
      "userId": "03216459765114495593"
     },
     "user_tz": 180
    },
    "id": "171BECu4aq9q"
   },
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout \n",
    "from tensorflow.keras.layers import Rescaling, RandomFlip, RandomRotation, RandomZoom\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 11772,
     "status": "ok",
     "timestamp": 1651758747996,
     "user": {
      "displayName": "Sarvio Valente",
      "userId": "03216459765114495593"
     },
     "user_tz": 180
    },
    "id": "mWma_bQUbJUE"
   },
   "outputs": [],
   "source": [
    "# Criando caminhos para acesso a pasta das imagens\n",
    "\n",
    "# Caminho das imagens de treinamento e validação\n",
    "pasta = 'C:/Users/mbfio/imagens_celulas_completo/'\n",
    "\n",
    "# Caminho das imagens de teste (foram separadas 5000 imagens para essa função)\n",
    "teste = 'C:/Users/mbfio/imagens_celulas_teste/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o tamanho das imagens \n",
    "\n",
    "SIZE = 64\n",
    "\n",
    "TAM = (SIZE, SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22558 files belonging to 2 classes.\n",
      "Using 18047 files for training.\n"
     ]
    }
   ],
   "source": [
    "# Criando o dataset de treinamento\n",
    "# Foi utilizado a função 'image_dataset_from_directory' somente para fins de aprendizado\n",
    "\n",
    "train_ds = image_dataset_from_directory(pasta, validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(SIZE, SIZE),\n",
    "  batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22558 files belonging to 2 classes.\n",
      "Using 4511 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Criando o dataset de validação, utilizando 20% das fotos da pasta\n",
    "\n",
    "valid_ds = image_dataset_from_directory(pasta, validation_split=0.2, \n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(SIZE, SIZE),\n",
    "  batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negativos', 'positivos']\n"
     ]
    }
   ],
   "source": [
    "# Mostrando o nome das classes do banco de dados\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64, 3)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "# Mostrando o tamanho dos pacotes de imagens e formato das imagens\n",
    "\n",
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Criando o dataset de teste\n",
    "\n",
    "test_ds = image_dataset_from_directory(teste, seed=123,\n",
    "  image_size=(SIZE, SIZE),\n",
    "  batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negativos', 'positivos']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrando o nome das classes do banco de dados de teste\n",
    "\n",
    "test_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 64, 64, 3)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "# Mostrando o tamanho dos pacotes de imagens e formato das imagens\n",
    "\n",
    "for image_batch, labels_batch in test_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 766,
     "status": "ok",
     "timestamp": 1651761857713,
     "user": {
      "displayName": "Sarvio Valente",
      "userId": "03216459765114495593"
     },
     "user_tz": 180
    },
    "id": "TpFcEh4ZlNb7",
    "outputId": "ffd2cbc4-d01e-4649-da65-068f1c7638f5"
   },
   "outputs": [],
   "source": [
    "# Criando a estrutura da rede neural convolucional\n",
    "\n",
    "modelo = Sequential()\n",
    "\n",
    "# Normalização dos dados das imagens\n",
    "modelo.add(Rescaling(1./255))\n",
    "\n",
    "# Aumento de dados\n",
    "modelo.add(RandomFlip(\"horizontal_and_vertical\", seed=0))\n",
    "modelo.add(RandomRotation(0.2, seed=0))\n",
    "modelo.add(RandomZoom(0.2, 0.2, fill_mode='nearest', seed=0))\n",
    "\n",
    "# Camadas convolucionais\n",
    "modelo.add(Conv2D(32, kernel_size = (3,3), activation = 'relu', padding = 'same', input_shape = TAM))\n",
    "modelo.add(MaxPooling2D(pool_size = (2,2)))\n",
    "modelo.add(Dropout(rate = 0.2))\n",
    "modelo.add(Conv2D(32, kernel_size = (3,3), activation = 'relu', padding = 'same'))\n",
    "modelo.add(MaxPooling2D(pool_size = (2,2)))\n",
    "modelo.add(Dropout(rate = 0.2))\n",
    "modelo.add(Conv2D(32, kernel_size = (3,3), activation = 'relu', padding = 'same'))\n",
    "modelo.add(MaxPooling2D(pool_size = (2,2)))\n",
    "modelo.add(Dropout(rate = 0.2))\n",
    "modelo.add(Conv2D(32, kernel_size = (3,3), activation = 'relu', padding = 'same'))\n",
    "modelo.add(MaxPooling2D(pool_size = (2,2)))\n",
    "modelo.add(Dropout(rate = 0.2))\n",
    "modelo.add(Conv2D(32, kernel_size = (3,3), activation = 'relu', padding = 'same'))\n",
    "modelo.add(MaxPooling2D(pool_size = (2,2)))\n",
    "modelo.add(Dropout(rate = 0.2))\n",
    "\n",
    "modelo.add(Flatten())\n",
    "\n",
    "# Camadas totalmente conectadas\n",
    "modelo.add(Dense(512, activation = 'relu'))\n",
    "modelo.add(BatchNormalization(axis=-1))\n",
    "modelo.add(Dropout(rate = 0.2))\n",
    "modelo.add(Dense(256, activation = 'relu'))\n",
    "modelo.add(BatchNormalization(axis=-1))\n",
    "modelo.add(Dropout(rate = 0.2))\n",
    "modelo.add(Dense(1, activation= 'sigmoid'))\n",
    "\n",
    "# Compilando o modelo\n",
    "modelo.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22096,
     "status": "ok",
     "timestamp": 1651761886402,
     "user": {
      "displayName": "Sarvio Valente",
      "userId": "03216459765114495593"
     },
     "user_tz": 180
    },
    "id": "2kM3K7N0oBCF",
    "outputId": "4f7aa236-0120-4cc6-bdb2-3cae4b5c5bbc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "282/282 [==============================] - 27s 86ms/step - loss: 0.7090 - accuracy: 0.6200 - val_loss: 1.3141 - val_accuracy: 0.5108\n",
      "Epoch 2/80\n",
      "282/282 [==============================] - 24s 84ms/step - loss: 0.6229 - accuracy: 0.6653 - val_loss: 1.1243 - val_accuracy: 0.5108\n",
      "Epoch 3/80\n",
      "282/282 [==============================] - 24s 84ms/step - loss: 0.5989 - accuracy: 0.6895 - val_loss: 0.9124 - val_accuracy: 0.5108\n",
      "Epoch 4/80\n",
      "282/282 [==============================] - 24s 84ms/step - loss: 0.2290 - accuracy: 0.9208 - val_loss: 0.1705 - val_accuracy: 0.9472\n",
      "Epoch 5/80\n",
      "282/282 [==============================] - 24s 85ms/step - loss: 0.1832 - accuracy: 0.9419 - val_loss: 0.1733 - val_accuracy: 0.9470\n",
      "Epoch 6/80\n",
      "282/282 [==============================] - 24s 85ms/step - loss: 0.1720 - accuracy: 0.9457 - val_loss: 0.1587 - val_accuracy: 0.9517\n",
      "Epoch 7/80\n",
      "282/282 [==============================] - 24s 85ms/step - loss: 0.1663 - accuracy: 0.9489 - val_loss: 0.1627 - val_accuracy: 0.9534\n",
      "Epoch 8/80\n",
      "282/282 [==============================] - 24s 86ms/step - loss: 0.1651 - accuracy: 0.9495 - val_loss: 0.1528 - val_accuracy: 0.9532\n",
      "Epoch 9/80\n",
      "282/282 [==============================] - 25s 87ms/step - loss: 0.1605 - accuracy: 0.9509 - val_loss: 0.1493 - val_accuracy: 0.9552\n",
      "Epoch 10/80\n",
      "282/282 [==============================] - 24s 85ms/step - loss: 0.1572 - accuracy: 0.9513 - val_loss: 0.1507 - val_accuracy: 0.9554\n",
      "Epoch 11/80\n",
      "282/282 [==============================] - 24s 86ms/step - loss: 0.1583 - accuracy: 0.9510 - val_loss: 0.1689 - val_accuracy: 0.9541\n",
      "Epoch 12/80\n",
      "282/282 [==============================] - 24s 86ms/step - loss: 0.1613 - accuracy: 0.9504 - val_loss: 0.1568 - val_accuracy: 0.9563\n",
      "Epoch 13/80\n",
      "282/282 [==============================] - 24s 85ms/step - loss: 0.1583 - accuracy: 0.9501 - val_loss: 0.1436 - val_accuracy: 0.9546\n",
      "Epoch 14/80\n",
      "282/282 [==============================] - 24s 85ms/step - loss: 0.1592 - accuracy: 0.9501 - val_loss: 0.1462 - val_accuracy: 0.9548\n",
      "Epoch 15/80\n",
      "282/282 [==============================] - 24s 85ms/step - loss: 0.1530 - accuracy: 0.9530 - val_loss: 0.1498 - val_accuracy: 0.9563\n",
      "Epoch 16/80\n",
      "282/282 [==============================] - 24s 86ms/step - loss: 0.1508 - accuracy: 0.9518 - val_loss: 0.1421 - val_accuracy: 0.9539\n",
      "Epoch 17/80\n",
      "282/282 [==============================] - 26s 90ms/step - loss: 0.1551 - accuracy: 0.9523 - val_loss: 0.1480 - val_accuracy: 0.9546\n",
      "Epoch 18/80\n",
      "282/282 [==============================] - 26s 90ms/step - loss: 0.1477 - accuracy: 0.9544 - val_loss: 0.1497 - val_accuracy: 0.9543\n",
      "Epoch 19/80\n",
      "282/282 [==============================] - 25s 87ms/step - loss: 0.1499 - accuracy: 0.9534 - val_loss: 0.1491 - val_accuracy: 0.9563\n",
      "Epoch 20/80\n",
      "282/282 [==============================] - 25s 88ms/step - loss: 0.1508 - accuracy: 0.9526 - val_loss: 0.1466 - val_accuracy: 0.9559\n",
      "Epoch 21/80\n",
      "282/282 [==============================] - 24s 86ms/step - loss: 0.1478 - accuracy: 0.9560 - val_loss: 0.1506 - val_accuracy: 0.9559\n",
      "Epoch 22/80\n",
      "282/282 [==============================] - 25s 86ms/step - loss: 0.1509 - accuracy: 0.9532 - val_loss: 0.1549 - val_accuracy: 0.9543\n",
      "Epoch 23/80\n",
      "282/282 [==============================] - 25s 87ms/step - loss: 0.1461 - accuracy: 0.9550 - val_loss: 0.1498 - val_accuracy: 0.9546\n",
      "Epoch 24/80\n",
      "282/282 [==============================] - 25s 87ms/step - loss: 0.1464 - accuracy: 0.9552 - val_loss: 0.1469 - val_accuracy: 0.9559\n",
      "Epoch 25/80\n",
      "282/282 [==============================] - 25s 87ms/step - loss: 0.1483 - accuracy: 0.9536 - val_loss: 0.1639 - val_accuracy: 0.9572\n",
      "Epoch 26/80\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.9551Restoring model weights from the end of the best epoch: 16.\n",
      "282/282 [==============================] - 25s 88ms/step - loss: 0.1438 - accuracy: 0.9551 - val_loss: 0.1469 - val_accuracy: 0.9543\n",
      "Epoch 26: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Treinamento do modelo\n",
    "\n",
    "parada = EarlyStopping(monitor = 'val_loss', patience=10, restore_best_weights=True, verbose=True)\n",
    "\n",
    "history = modelo.fit(train_ds,validation_data=valid_ds, verbose = 1, epochs = 80, callbacks=parada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurária do modelo: 0.9467999935150146\n"
     ]
    }
   ],
   "source": [
    "# Acurácia do modelo treinado nos dados de teste\n",
    "\n",
    "_,score = modelo.evaluate(test_ds, batch_size=50, verbose=0)\n",
    "\n",
    "print('Acurária do modelo:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOWXma9dKh3B49KKPwl73Py",
   "collapsed_sections": [],
   "mount_file_id": "1jwEphPck5fH8w2FsN8nSWLJYcAmLE1_D",
   "name": "Aula.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
